"""1. Getting Started with FCN Pre-trained Models
==============================================

This is a quick demo of using GluonCV FCN model on PASCAL VOC dataset.
Please follow the `installation guide <../index.html>`_ to install MXNet and GluonCV if not yet.
"""
import mxnet as mx
from mxnet import image
from PIL import Image
from mxnet.gluon.data.vision import transforms

import gluoncv
import numpy as np
import makeImage
# using cpu
ctx = mx.cpu()



##############################################################################
# Prepare the image
# -----------------
#
# download the example image
#url = 'https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/segmentation/voc_examples/1.jpg'
filename = 'example.jpg'
#gluoncv.utils.download(url, filename)

##############################################################################
# load the image
path = 'C:\\Users\\AAA\\Desktop\\resnet\\Done\\fcnTest\\'
filename = '747_496_L_B_0_modify.jpg'
img = image.imread(path+filename)
img = image.imresize(img,1280,720)

from matplotlib import pyplot as plt
plt.imshow(img.asnumpy())
plt.show()

##############################################################################
# normalize the image using dataset mean
transform_fn = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([.485, .456, .406], [.229, .224, .225])
])
img = transform_fn(img)
img = img.expand_dims(0).as_in_context(ctx)


##############################################################################
# Load the pre-trained model and make prediction
# ----------------------------------------------
#
# get pre-trained model
model = gluoncv.model_zoo.get_fcn(dataset='pascal_voc', backbone='resnet50', pretrained=False)
model2 = gluoncv.model_zoo.get_fcn(dataset='pascal_voc', backbone='resnet50', pretrained=False)

#if os.path.isfile(args.resume):
directory = "runs/pascal_voc/checkpoint_190725.params"
dir_50_aug2 = "C:\\Users\\AAA\\Desktop\\resnet\\Done\\fcnTest\\checkpoint_resnet50_0.001_20_0.9_e=50_d_5_plateaug2.params"##2400
dir_food = "C:\\Users\\AAA\\Desktop\\resnet\\Done\\fcnTest\\checkpoint_resnet50_0.001_20_0.9_e=100_d_5_food.params"


model.load_parameters(dir_50_aug2, ctx = ctx)
model2.load_parameters(dir_food, ctx = ctx)


##############################################################################
# make prediction using single scale
output = model.demo(img)
output2 = model2.demo(img)

allMenuPath = "C:\\Users\\AAA\\Desktop\\resnet\\Done\\fcnTest\\class_names.txt" ##  전체 메뉴
allMenu = open(allMenuPath,'r')
MenuPath = "C:\\Users\\AAA\\Desktop\\resnet\\Done\\fcnTest\\menu.txt" ##테스트할 식단 메뉴
sMenu = open(MenuPath,'r')
all = []
select = []
newcnt = 0#######################신메뉴 개수
newname = []#####################신메뉴 이름
while True:
    line = allMenu.readline()
    if not line:break
    all.append(line)
while True:
    line = sMenu.readline()
    if not line:break
    select.append(line)
    if line not in all:
        newcnt += 1
        newname.append(line)
allMenu.close()
sMenu.close()
menu = []

for i in range(len(select)):
    #print(select[i])
    if select[i] in all:
        menu.append(all.index(select[i]))

#print(menu)

#menu = [0,1,4,5,6,7]#####0327morning
menu2 = [0,1,2,3]

############################################insert menu
######################################################################################

ex= mx.nd.exp(output-np.max(output))
ex2= mx.nd.exp(output2-np.max(output2))


new = mx.nd.zeros_like(ex)
new2 = mx.nd.zeros_like(ex2)
m1 = ex.asnumpy()
m2 = ex2.asnumpy()

new = new.asnumpy()
new2 = new2.asnumpy()

max1 = np.max(m1)
max2 = np.max(m2)

new[:,menu] = max1
new2[:,menu2] = max2

insert_menu = np.where(m1>new, 0, m1)####### new보다 크면 0 아니면 그대로
insert_menu = insert_menu/np.sum(insert_menu,axis=1)#############

insert_menu2 = np.where(m2>new2, 0, m2)####### new보다 크면 0 아니면 그대로
insert_menu2 = insert_menu2/np.sum(insert_menu2,axis=1)#############
#####################################menu

orig = insert_menu######model 1
orig2 = insert_menu2######model 1


threshold = 0.5

orig = np.where(orig<=threshold,0,1)
orig2 = np.where(orig2<=threshold,0,1)


orig[:,0] = 1-np.count_nonzero(orig, axis=1)
orig2[:,0] = 1-np.count_nonzero(orig2, axis=1) ##food
######################################################모델 클래스별 TF 들어있는 arr
if newcnt>0:
    #print('11111')
    plateidx = 17
    spoonidx = 7

    food = makeImage.foodImage(orig2)
    menus = makeImage.allmenuImage(orig, spoonidx, plateidx)
    new = makeImage.food_notinAllmenu(food, menus, filename)
    contournew = makeImage.getNewContour(new)
    ###############신메뉴의 contour
##########################################################################################
    #############------------------신메뉴 포함 사진 Json 파일 생성-------------------
    import copy
    import json
    foodmenu = copy.deepcopy(menu)
    foodmenu.remove(0)
    foodmenu.remove(spoonidx)
    foodmenu.remove(plateidx)
    ########################class들 중 음식종류만 남김
    f = open("C:\\Users\\AAA\\Desktop\\resnet\\labelme-master\\examples\\semantic_segmentation\\"
             "data_annotated\\"+filename.replace('jpg','json'), 'w')

    data = makeImage.makeNewJson(filename, orig.shape[2], orig.shape[3])

    spoon = makeImage.arrToImage(orig[0][spoonidx])
    contours = makeImage.getContour(spoon)
    data = makeImage.addContourJson(contours, all[spoonidx].replace("\n",""),data)######spoon Json파일

    plate = makeImage.arrToImage(orig[0][[plateidx]])
    contours = makeImage.getContour(plate)
    data = makeImage.addContourJson(contours, all[plateidx].replace("\n", ""), data)#####plate Json파일

    for i in foodmenu:
        one = makeImage.arrToImage(orig[0][i])
        contours = makeImage.getContour(one)
        data = makeImage.addContourJson(contours, all[i].replace("\n",""),data)######신메뉴 제외 음식Json파일

    data = makeImage.addContourJson(contournew, newname[0].replace("\n", ""), data)#####신메뉴 Json파일
    json.dump(data,f)
    f.close()

####################################################################################################
orig = mx.nd.array(orig)
orig2 = mx.nd.array(orig2)

predict = mx.nd.squeeze(mx.nd.argmax(orig, 1)).asnumpy()
predict2 = mx.nd.squeeze(mx.nd.argmax(orig2, 1)).asnumpy()
##############################################################################
# Add color pallete for visualization
from gluoncv.utils.viz import get_color_pallete
import matplotlib.image as mpimg
mask = get_color_pallete(predict, 'pascal_voc')
mask2 = get_color_pallete(predict2, 'pascal_voc')

mask.save('output.png')
mask2.save('output2.png')


##############################################################################
# show the predicted mask
mmask = mpimg.imread('output.png')
mmask2 = mpimg.imread('output2.png')

#mmask2 = mpimg.imread('output2.png')######
plt.imshow(mmask)
plt.show()
plt.imshow(mmask2)
plt.show()

